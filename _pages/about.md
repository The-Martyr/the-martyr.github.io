---
permalink: /
title: "About Me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

I'm **Guanyu Zhou**, a research intern at **Princeton University**, currently a senior undergraduate student. I am applying for the Fall 2026 PhD program in CS/AI, and this is my [CV](/files/Resume.pdf).

I am currently Working with Professor [Zhuang Liu](https://liuzhuang13.github.io/) at Princeton University. My current research interests are **VLMs/MLLMs (Understanding, Generation, and Reasoning)**, with a current focus on **data**. I hope to learn from VLMs/MLLMs, reflect on its bottlenecks, and explore the prototype of the next generation of intelligent systems.

Prior to this, I did a research internship at the [NLPGroup](https://xuminghu.github.io/) of **HKUST(GZ)**, exploring the perceptual flaws of MLLMs. I also had an unforgettable research time at [AIMlab](https://xiangroup.github.io/), where I worked on problems related to video understanding / action recognition.

My ultimate goal is to build **a multimodal, scalable, dataset-free, continuously learning, and self-iterating intelligent system**. Feel free to email me to discuss issues in related fields!üòÑ

<br>
# üìÖ News
* [2025.11] [OmniDPO](https://arxiv.org/abs/2509.00723) accepted by AAAI 2026.
* [2025.03] I made a sharing at [AI TIME](https://www.bilibili.com/video/BV1YkRAYVEHy/?vd_source=ffc139b7b13aa7195dd7b37795efa6a9), welcome to watch!
* [2025.01] Our paper [CausalMM](https://arxiv.org/abs/2410.04780) has been accepted to **ICLR 2025**, see you in Singapore!
* [2024.07] I am visiting HKUST(GZ) under the supervision of Professor [Xuming Hu](https://xuminghu.github.io)!

<br>
# üìù Publications

<div style="display: flex; align-items: center; margin-bottom: 20px;">
  <div style="flex: 1; padding-left: 0px;">
    <img src="/images/causalmm.png" alt="Flowchart" style="max-width: 100%;">
  </div>
  <div style="width: 60%; padding-left: 10px;">
    <p><strong>[ICLR 2025] Mitigating Modality Prior-Induced Hallucinations in Multimodal Large Language Models via Deciphering Attention Causality</strong></p>
    <p><strong>Guanyu Zhou</strong>, Yibo Yan, Xin Zou, Kun Wang, Aiwei Liu, Xuming Hu</p>
    <a href="https://arxiv.org/pdf/2410.04780" target="_blank"><button>PDF</button></a> 
    <a href="https://github.com/The-Martyr/CausalMM" target="_blank"><button>Code</button></a>
    <a href="https://www.bilibili.com/video/BV1YkRAYVEHy/?vd_source=ffc139b7b13aa7195dd7b37795efa6a9" target="_blank"><button>Talk</button></a> 
    <a href="https://iclr.cc/virtual/2025/poster/30629" target="_blank"><button>ICLR</button></a>
  </div>
</div>

<style>
p {
    margin: 0; /* Remove default margin */
    padding: 0; /* Remove default padding */
}
button {
  background-color: #4CAF50; /* Green background */
  border: none; /* No border */
  color: white; /* White text */
  padding: 10px 20px; /* Padding */
  text-align: center; /* Centered text */
  text-decoration: none; /* No underline */
  display: inline-block; /* Inline block */
  font-size: 16px; /* Font size */
  margin: 4px 2px; /* Margin */
  cursor: pointer; /* Pointer cursor */
  border-radius: 8px; /* Rounded corners */
}
</style>

<div style="display: flex; align-items: center; margin-bottom: 20px;">
  <div style="flex: 1; padding-left: 0px;">
    <img src="/images/omni.png" alt="Flowchart" style="max-width: 100%;">
  </div>
  <div style="width: 60%; padding-left: 10px;">
    <p><strong>[AAAI 2026] OmniDPO: A Preference Optimization Framework to Address Omni-Modal Hallucination</strong></p>
    <p>Junzhe Chen, Tianshu Zhang, Shiyu Huang, Yuwei Niu, Chao Sun, Rongzhou Zhang, <strong>Guanyu Zhou</strong>, Lijie Wen, Xuming Hu</p>
    <a href="https://arxiv.org/abs/2509.00723" target="_blank"><button>PDF</button></a> 
    <a href="https://anonymous.4open.science/r/OmniDPO-7E3C/README.md" target="_blank"><button>Code</button></a>
  </div>
</div>

<style>
p {
    margin: 0; /* Remove default margin */
    padding: 0; /* Remove default padding */
}
button {
  background-color: #4CAF50; /* Green background */
  border: none; /* No border */
  color: white; /* White text */
  padding: 10px 20px; /* Padding */
  text-align: center; /* Centered text */
  text-decoration: none; /* No underline */
  display: inline-block; /* Inline block */
  font-size: 16px; /* Font size */
  margin: 4px 2px; /* Margin */
  cursor: pointer; /* Pointer cursor */
  border-radius: 8px; /* Rounded corners */
}
</style>

<div style="display: flex; align-items: center; margin-bottom: 20px;">
  <div style="flex: 1; padding-left: 0px;">
    <img src="/images/foundry.png" alt="Flowchart" style="max-width: 100%;">
  </div>
  <div style="width: 60%; padding-left: 10px;">
    <p><strong>[Preparing] A Data-Centric Task for Enhancing Multimodal LLMs on Vision-Centric Tasks</strong></p>
    <p><strong>Guanyu Zhou</strong> with <a href="https://github.com/zlab-princeton" target="_blank">zlab</a>@Princeton University</p>
    <a href="#"><button>Preparing</button></a>
  </div>
</div>

<div style="display: flex; align-items: center; margin-bottom: 20px;">
  <div style="flex: 1; padding-left: 0px;">
    <img src="/images/mani.png" alt="Flowchart" style="max-width: 100%;">
  </div>
  <div style="width: 60%; padding-left: 10px;">
    <p><strong>[CVPR 2026 Under Review] An Efficient Manifold-Hypothesis-Based Dimensional Analysis Algorithm and Its Applications in MLLMs</strong></p>
    <p><strong>Guanyu Zhou</strong>, Yonghua Hei, Yibo Yan, Xin Zou, Junzhe Chen, Xuming Hu</p>
    <a href="#"><button>Preparing</button></a>
  </div>
</div>


<div style="display: flex; align-items: center; margin-bottom: 20px;">
  <div style="flex: 1; padding-left: 0px;">
    <img src="/images/cml.png" alt="Flowchart" style="max-width: 100%;">
  </div>
  <div style="width: 60%; padding-left: 10px;">
    <p><strong>[ICML 2026 Under Review] CML-Bench: A Framework for Evaluating and Enhancing LLM-Powered Movie Scripts Generation</strong></p>
    <p>Mingzhe Zheng, Dingjie Song, <strong>Guanyu Zhou</strong>, Jun You, Jiahao Zhan, Xuran Ma, Xinyuan Song, Ser-Nam Lim, Qifeng Chen, Harry Yang</p>
    <a href="https://arxiv.org/abs/2510.06231" target="_blank"><button>PDF</button></a> 
    <a href="https://github.com/DuNGEOnmassster/CML-Bench" target="_blank"><button>Code</button></a>
    <a href="https://huggingface.co/datasets/songdj/CML-Bench" target="_blank"><button>Dataset</button></a>
  </div>
</div>

<style>
p {
    margin: 0; /* Remove default margin */
    padding: 0; /* Remove default padding */
}
button {
  background-color: #4CAF50; /* Green background */
  border: none; /* No border */
  color: white; /* White text */
  padding: 10px 20px; /* Padding */
  text-align: center; /* Centered text */
  text-decoration: none; /* No underline */
  display: inline-block; /* Inline block */
  font-size: 16px; /* Font size */
  margin: 4px 2px; /* Margin */
  cursor: pointer; /* Pointer cursor */
  border-radius: 8px; /* Rounded corners */
}
</style>

<div style="display: flex; align-items: center; margin-bottom: 20px;">
  <div style="flex: 1; padding-left: 0px;">
    <img src="/images/car.png" alt="Flowchart" style="max-width: 100%;">
  </div>
  <div style="width: 60%; padding-left: 10px;">
    <p><strong>OccludeNet: A Causal Journey into Mixed-View Actor-Centric Video Action Recognition under Occlusions</strong></p>
    <p><strong>Guanyu Zhou</strong>, Wenxuan Liu, Wenxin Huang, Xuemei Jia, Xian Zhong, Chia-Wen Lin</p>
    <a href="https://arxiv.org/pdf/2411.15729" target="_blank"><button>PDF</button></a> 
    <a href="https://github.com/The-Martyr/OccludeNet-Dataset" target="_blank"><button>Code</button></a>
  </div>
</div>

<style>
p {
    margin: 0; /* Remove default margin */
    padding: 0; /* Remove default padding */
}
button {
  background-color: #4CAF50; /* Green background */
  border: none; /* No border */
  color: white; /* White text */
  padding: 10px 20px; /* Padding */
  text-align: center; /* Centered text */
  text-decoration: none; /* No underline */
  display: inline-block; /* Inline block */
  font-size: 16px; /* Font size */
  margin: 4px 2px; /* Margin */
  cursor: pointer; /* Pointer cursor */
  border-radius: 8px; /* Rounded corners */
}
</style>




<br>
# üìá Experience

<div style="margin-top: 40px; display: flex; align-items: center; margin-bottom: 20px;"> 
  <div style="flex: 1; padding-left: 40px;">
    <img src="/images/princeton.png" alt="HKUST" style="max-width: 80%; height: auto;">
  </div>
  <div style="flex: 2; padding-left: 10px;">
    <p>[2024.7] <strong>Princeton University / ZLab</strong></p>
    <p>Topic: Sythetic Data and GenAI</p>
  </div>
</div>

<div style="margin-top: 40px; display: flex; align-items: center; margin-bottom: 20px;"> 
  <div style="flex: 1; padding-left: 40px;">
    <img src="/images/68747470733a2f2f686b7573742e6564752e686b2f73697465732f64656661756c742f66696c65732f696d616765732f5553545f4c332e737667.svg" alt="HKUST" style="max-width: 80%; height: auto;">
  </div>
  <div style="flex: 2; padding-left: 10px;">
    <p>[2024.7] <strong>HKUST(GZ) / AI Thrust</strong></p>
    <p>Topic: Bias in Model Prior Knowledge</p>
  </div>
</div>

<div style="display: flex; align-items: center; margin-bottom: 20px;">
  <div style="flex: 1; padding-left: 40px;">
    <img src="/images/AIMLab.jpg" alt="AIMLab" style="max-width: 80%; width: 200px; height: auto;">
  </div>
  <div style="flex: 2; padding-left: 10px;">
    <p>[2023.7] <strong>AIMLab / Action Recogniton Group</strong></p>
    <p>Topic: Bias in the Data (Learning Process)</p>
  </div>
</div>



<br>
# ‚úç Services

### Reviewer

* IEEE International Conference on Computer Vision 2025 (ICCV 2025)
* IEEE International Conference on Multimedia & Expo 2025 (ICME 2025)
* IEEE Transactions on Circuits and Systems for Video Technology (TCSVT)

### Management

* Deputy Director of Competition Management Center of the School's Innovation and Entrepreneurship Department (2023-2024)



<br>
# üë®‚Äçüè´ Talks

* AI TIME Online Pre-Session (ICLR 2025) [[watch on Bilibili]](https://www.bilibili.com/video/BV1YkRAYVEHy/?vd_source=ffc139b7b13aa7195dd7b37795efa6a9)




<div style="margin-top: 100px;"></div>

<div style="display:none;">
    <script type="text/javascript" id="mapmyvisitors" src="//mapmyvisitors.com/map.js?d=8MhgTWHJEZzdE82Bb-wBII3RuujWQtydOxS12ZLFdM8&cl=ffffff&w=a"></script>
</div>



